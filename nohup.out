Loading data from samanantar_4950k_filtered.tsv...
Loaded 4891173 translation pairs.
Training set: 4402055 examples
Validation set: 489118 examples
Loading T5 tokenizer and model...
Traceback (most recent call last):
  File "/fab3/btech/2022/arya.sahu22b/CS300-ProjectI/CS300-Project-I/T5/finetune_t5.py", line 367, in <module>
    main()
  File "/fab3/btech/2022/arya.sahu22b/CS300-ProjectI/CS300-Project-I/T5/finetune_t5.py", line 281, in main
    tokenizer = T5Tokenizer.from_pretrained("t5-base")
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/fab3/btech/2022/arya.sahu22b/miniconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 1736, in __getattribute__
    requires_backends(cls, cls._backends)
  File "/fab3/btech/2022/arya.sahu22b/miniconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 1724, in requires_backends
    raise ImportError("".join(failed))
ImportError: 
T5Tokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the
installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones
that match your environment. Please note that you may need to restart your runtime after installation.

